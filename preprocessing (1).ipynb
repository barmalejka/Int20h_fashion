{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport cv2\nimport os\nimport json\n\nprint(os.listdir(\"../input\"))\nprint(os.listdir(\"../input/imaterialist-fashion-2019-FGVC6\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/imaterialist-fashion-2019-FGVC6/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Category'] = data['ClassId'].apply(lambda x: int(x.split(\"_\")[0]))\ndata['Attributes'] = data['ClassId'].apply(lambda x: \"_\".join(x.split(\"_\")[1:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_names = data.ImageId.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test, _, _ = train_test_split(img_names, img_names, test_size=0.21, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['dataset'] = 'train'\ndata.loc[data['ImageId'].isin(test), 'dataset'] = 'test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Area'] = data.apply(lambda x: sum([int(a) for i, a in enumerate(x['EncodedPixels'].split()) if i % 2 ==1]), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = data[data['dataset']=='train'].boxplot(column=['Area'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Min area:', data[data['dataset']=='train'].Area.min())\nprint('Max area:', data[data['dataset']=='train'].Area.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"area_percentile = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0, int(data[data['dataset']=='train'].Area.quantile(0.75)), 1000):\n    area_percentile[i] = data[(data['dataset']=='train')&\n                               (data['Area']<=i)].shape[0] / data[data['dataset']=='train'].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lists = sorted(area_percentile.items()) # sorted by key, return a list of tuples\n\nx, y = zip(*lists) # unpack a list of pairs into two tuples\n\nplt.plot(x, y)\nplt.xlabel('Area')\nplt.ylabel('% of objects in train dataset')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"small_lists = [x for x in lists if x[1] < 0.4]\n\nx, y = zip(*small_lists) # unpack a list of pairs into two tuples\n\nplt.plot(x, y)\nplt.xlabel('Area')\nplt.ylabel('% of objects in train dataset')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('% of objects with area > 10 000')\nprint(data[(data['dataset']=='train')& (data['Area']>=10000)].shape[0] / data[(data['dataset']=='train')].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total number of train images:', data[(data['dataset']=='train')].ImageId.nunique())\nprint('Number of train images with large object on them:', data[(data['dataset']=='train')& (data['Area']>=10000)].ImageId.nunique())\nprint('Number of train images without atributes:', data[(data['dataset']=='train')&(data['Attributes']=='')].ImageId.nunique())\nprint('Number of train images with large object on them and without atributes:', data[(data['dataset']=='train')&(data['Area']>=1000)&(data['Attributes']=='')].ImageId.nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total number of objects in train set:', len(data[(data['dataset']=='train')]))\nprint('Total number of objects in truncated train set:', len(data[(data['dataset']=='train')&(data['Area']>=1000)&(data['Attributes']=='')]))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_truncated = pd.concat([data[(data['dataset']=='train')&(data['Area']>=1000)&(data['Attributes']=='')],\n                               data[data['dataset']=='test']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Nubmer of objects in original dataset: ', len(data))\nprint('Nubmer of objects in truncated dataset: ', len(data_truncated))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_truncated.to_csv('train_df_truncated.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groupby_category = data[(data['dataset']=='train')].groupby('Category')['ImageId'].count()\ngroupby_category.index = map(int, groupby_category.index)\ngroupby_category = groupby_category.sort_index()\ngroupby_category[:5]\n\nfig = plt.figure(figsize=(10, 4))\nx = groupby_category.index\ny = groupby_category.values\n\nsns.barplot(x,y)\nplt.title(\"Number of images by category\", fontsize=20)\nplt.xlabel(\"Category\", fontsize=20)\nplt.ylabel(\"# of images\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}